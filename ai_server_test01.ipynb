{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd3691c-94d1-4b66-b6f0-ff884e60f699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4236e97-a626-4a81-b988-8f51df6c444b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (0.116.1)\n",
      "Requirement already satisfied: uvicorn in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (0.35.0)\n",
      "Requirement already satisfied: python-multipart in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (0.0.20)\n",
      "Requirement already satisfied: moviepy in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: openai-whisper in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (20250625)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from fastapi) (0.47.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from fastapi) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from fastapi) (4.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from uvicorn) (8.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (5.2.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (2.2.6)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (1.1.1)\n",
      "Requirement already satisfied: pillow<12.0,>=9.2.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (11.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from proglog<=1.0.0->moviepy) (4.67.1)\n",
      "Requirement already satisfied: more-itertools in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from openai-whisper) (10.7.0)\n",
      "Requirement already satisfied: numba in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from openai-whisper) (0.61.2)\n",
      "Requirement already satisfied: tiktoken in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from openai-whisper) (0.11.0)\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from openai-whisper) (2.6.0+cu118)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from tiktoken->openai-whisper) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.6.15)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from torch->openai-whisper) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from torch->openai-whisper) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn python-multipart moviepy openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b3365-4984-4bed-85b3-96b247e09897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already satisfied: fastapi in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (0.116.1)\n",
      "Requirement already satisfied: uvicorn in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (0.35.0)\n",
      "Requirement already satisfied: python-multipart in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (0.0.20)\n",
      "Requirement already satisfied: moviepy in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: openai-whisper in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (20250625)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from fastapi) (0.47.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from fastapi) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from fastapi) (4.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from uvicorn) (8.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (5.2.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (2.2.6)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (1.1.1)\n",
      "Requirement already satisfied: pillow<12.0,>=9.2.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from moviepy) (11.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from proglog<=1.0.0->moviepy) (4.67.1)\n",
      "Requirement already satisfied: more-itertools in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from openai-whisper) (10.7.0)\n",
      "Requirement already satisfied: numba in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from openai-whisper) (0.61.2)\n",
      "Requirement already satisfied: tiktoken in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from openai-whisper) (0.11.0)\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from openai-whisper) (2.6.0+cu118)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from tiktoken->openai-whisper) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.6.15)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from torch->openai-whisper) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from torch->openai-whisper) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env01\\lib\\site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [21120]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_video 시작\n",
      "sst된 음성 :  저의 강점은 다양한 사람과 원활하게 소통하는 커뮤니케이션 능력입니다. 동아리플렉스에서 팀 간 협업을 조율하며 웬만한 결과를 이끌어낸 경험이 있습니다. 반면 약점은 디테일에 지나치게 집중하는 경향입니다. 이를 보완하기 위해 우선순위 설정과 일정 단위의 루틴 실천을 하고 있습니다.\n",
      "답변 생성중 ~~~\n",
      "GPT4All 답변 (영어):\n",
      "**Answer:**\n",
      "\n",
      "Certainly! Here is the step-by-step explanation based on your thought process:\n",
      "\n",
      "1. **Strengths Identification**: \n",
      "   - The candidate highlights effective communication skills as their primary strength, emphasizing their ability to work well with diverse individuals. This is a valuable trait in most professional environments.\n",
      "\n",
      "2. **Example Provided**:\n",
      "   - They provide an example from their school's Harry Potter club where they led team collaborations and achieved successful results. This demonstrates practical leadership experience.\n",
      "\n",
      "3. **Weakness Acknowledgment**:\n",
      "   - The candidate identifies being overly detail-oriented as a weakness, which can be both beneficial and detrimental depending on the role. It is particularly useful in roles requiring precision but may hinder decision-making in strategic positions.\n",
      "\n",
      "4. **Improvement Strategies**:\n",
      "   - They mention working on prioritizing tasks and establishing review routines to mitigate their tendency towards over-detail orientation. This shows self-awareness and initiative.\n",
      "\n",
      "5. **Areas for Improvement**:\n",
      "   - The response could be enhanced by providing more specific examples of how their strengths align with the company's values.\n",
      "   - Connecting past experiences directly to the job they're applying for would strengthen the answer, making it more relevant and tailored.\n",
      "\n",
      "6. **Turning Weakness into Strength**:\n",
      "   - Instead of just listing strategies like task prioritization and routine reviews, the candidate could provide specific instances where their attention to detail has positively impacted projects or tasks.\n",
      "   - They might also frame this weakness as an area of growth where they have shown progress or implemented successful strategies.\n",
      "\n",
      "7. **Conclusion**:\n",
      "   - With these adjustments, focusing on aligning strengths with company values and providing concrete examples of overcoming weaknesses, the candidate's response could become even more compelling.\n",
      "\n",
      "By following this structured approach, the candidate can present a well-rounded and impactful answer to the \"What are your strengths and weaknesses?\" question in their job interview.\n",
      "\n",
      "번역 중...\n",
      "\n",
      "번역된 답변 (한국어):\n",
      "**답변:**\n",
      "\n",
      "틀림없이! 다음은 생각 과정을 기반으로 한 단계별 설명입니다.\n",
      "\n",
      "1. ** 강점 식별 ** : \n",
      "   - 후보자는 효과적인 의사 소통 기술을 주요 강점으로 강조하여 다양한 개인과 잘 일할 수있는 능력을 강조합니다. 이것은 대부분의 전문 환경에서 귀중한 특성입니다.\n",
      "\n",
      "2. ** 예제 제공 ** :\n",
      "   - 그들은 학교의 해리포터 클럽 (Harry Potter Club)에서 팀 협력을 이끌고 성공적인 결과를 얻었습니다. 이것은 실용적인 리더십 경험을 보여줍니다.\n",
      "\n",
      "3. ** 약점 승인 ** :\n",
      "   - 후보자는 지나치게 상세 지향을 약점으로 식별하며, 이는 역할에 따라 유익하고 해로운 일 수 있습니다. 정밀도가 필요한 역할에 특히 유용하지만 전략적 입장에서 의사 결정을 방해 할 수 있습니다.\n",
      "\n",
      "4. ** 개선 전략 ** :\n",
      "   - 그들은 과도한 분류 오리엔테이션에 대한 경향을 완화하기 위해 작업 우선 순위를 정하고 검토 루틴을 설정하는 것을 언급합니다. 이것은 자기 인식과 이니셔티브를 보여줍니다.\n",
      "\n",
      "5. ** 개선 영역 ** :\n",
      "   - 그들의 강점이 회사의 가치와 어떻게 일치하는지에 대한보다 구체적인 예를 제공함으로써 응답을 향상시킬 수 있습니다.\n",
      "   - 과거 경험을 신청하는 직무에 직접 연결하면 답이 강화되어 더욱 관련성이 높고 맞춤화됩니다.\n",
      "\n",
      "6. ** 약점을 힘으로 바꾸는 ** :\n",
      "   - 작업 우선 순위 및 일상적인 검토와 같은 전략을 나열하는 대신 후보자는 세부 사항에 대한 관심이 프로젝트 나 작업에 긍정적 인 영향을 미쳤던 특정 사례를 제공 할 수 있습니다.\n",
      "   - 그들은 또한이 약점을 진보를 보여 주거나 성공적인 전략을 구현 한 성장 영역으로 구성 될 수 있습니다.\n",
      "\n",
      "7. ** 결론 ** :\n",
      "   - 이러한 조정을 통해 회사 가치와 강점을 정렬하고 약점을 극복하는 구체적인 예를 제공하는 후보자의 반응이 더욱 매력적일 수 있습니다.\n",
      "\n",
      "이 구조화 된 접근 방식을 따르면 후보자는 \"당신의 강점과 약점은 무엇입니까?\"에 대해 다재다능하고 영향력있는 대답을 제시 할 수 있습니다. 면접에서 질문.\n",
      "\n",
      "질문-답변에 걸린 시간: 136.07초\n",
      "INFO:     127.0.0.1:55881 - \"POST /process_video HTTP/1.1\" 200 OK\n",
      "process_video 시작\n",
      "INFO:     127.0.0.1:55892 - \"POST /process_video HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "# (선택) Jupyter에서 실행 중일 때만 의존성 설치\n",
    "try:\n",
    "    get_ipython  # noqa\n",
    "    get_ipython().system('conda install ffmpeg -y')\n",
    "    get_ipython().system('pip install fastapi uvicorn python-multipart moviepy openai-whisper')\n",
    "except NameError:\n",
    "    pass\n",
    "from fastapi import FastAPI, File, UploadFile, Form\n",
    "from moviepy import VideoFileClip\n",
    "import whisper\n",
    "import torch\n",
    "import tempfile\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import traceback\n",
    "import subprocess   # 이전 오류 보완을 위해 유지\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "app = FastAPI()\n",
    "# Whisper 모델 로딩\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = whisper.load_model(\"large\", device=device)\n",
    "@app.post(\"/process_video\")\n",
    "async def process_video(file: UploadFile = File(...), text: str = Form(...)):\n",
    "    print(\"process_video 시작\")\n",
    "    try:\n",
    "        # 업로드 파일명/확장자 확인\n",
    "        filename = (file.filename or \"\").lower()\n",
    "        if not filename.endswith((\".mp4\", \".webm\")):\n",
    "            return {\"status\": \"error\", \"message\": \"mp4 또는 webm 파일만 지원합니다.\"}\n",
    "        ext = \".webm\" if filename.endswith(\".webm\") else \".mp4\"\n",
    "        # 업로드 파일을 메모리에서 읽기\n",
    "        video_bytes = await file.read()\n",
    "        # 임시로 업로드 확장자에 맞춰 저장\n",
    "        with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as temp_video:\n",
    "            temp_video.write(video_bytes)\n",
    "            video_path = temp_video.name\n",
    "        audio_path = None\n",
    "        # 1) MoviePy로 오디오 추출 시도\n",
    "        try:\n",
    "            with VideoFileClip(video_path) as video_clip:\n",
    "                audio_clip = video_clip.audio\n",
    "                if audio_clip is None:\n",
    "                    # 오디오 트랙 없음\n",
    "                    if os.path.exists(video_path):\n",
    "                        os.unlink(video_path)\n",
    "                    return {\"status\": \"error\", \"message\": \"동영상에서 음성을 찾을 수 없습니다.\"}\n",
    "                # Whisper 친화적 WAV(PCM s16le, Mono, 16kHz)로 저장\n",
    "                with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
    "                    audio_path = temp_audio.name\n",
    "                audio_clip.write_audiofile(\n",
    "                    audio_path,\n",
    "                    codec=\"pcm_s16le\",\n",
    "                    fps=16000,\n",
    "                    ffmpeg_params=[\"-ac\", \"1\"],  # mono\n",
    "                    verbose=False,\n",
    "                    logger=None,\n",
    "                )\n",
    "                audio_clip.close()\n",
    "        except Exception as moviepy_err:\n",
    "            # 2) MoviePy 실패 시 ffmpeg CLI로 안전 추출 (webm 코덱 호환성 대비)\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
    "                audio_path = temp_audio.name\n",
    "            cmd = [\n",
    "                \"ffmpeg\", \"-y\",\n",
    "                \"-i\", video_path,\n",
    "                \"-vn\",                    # 비디오 제거\n",
    "                \"-acodec\", \"pcm_s16le\",  # PCM s16\n",
    "                \"-ar\", \"16000\",          # 16kHz\n",
    "                \"-ac\", \"1\",              # mono\n",
    "                audio_path,\n",
    "            ]\n",
    "            try:\n",
    "                subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            except subprocess.CalledProcessError as ffmpeg_err:\n",
    "                # 임시 파일 정리 후 에러 반환\n",
    "                if os.path.exists(video_path):\n",
    "                    os.unlink(video_path)\n",
    "                if os.path.exists(audio_path):\n",
    "                    os.unlink(audio_path)\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"message\": f\"오디오 추출 실패 (MoviePy/ffmpeg): {moviepy_err} / {ffmpeg_err}\",\n",
    "                }\n",
    "        # 3) Whisper로 음성 → 텍스트 변환\n",
    "        result = model.transcribe(audio_path, fp16=(device == \"cuda\"))\n",
    "        transcribed_text = (result.get(\"text\") or \"\").strip()\n",
    "        # 임시 파일 정리\n",
    "        if os.path.exists(video_path):\n",
    "            os.unlink(video_path)\n",
    "        if audio_path and os.path.exists(audio_path):\n",
    "            os.unlink(audio_path)\n",
    "        \n",
    "        def translate_text(text, source_lang='en', target_lang='ko'):\n",
    "            base_url = 'https://lingva.ml/api/v1'\n",
    "            url = f\"{base_url}/{source_lang}/{target_lang}/{requests.utils.quote(text)}\"\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                return result.get('translation', '')\n",
    "            else:\n",
    "                print(f\"번역 API 호출 실패: {response.status_code}\")\n",
    "                return None\n",
    "        print(\"sst된 음성 : \", transcribed_text)\n",
    "        print(\"답변 생성중 ~~~\")\n",
    "        \n",
    "        API_URL = \"http://localhost:4891/v1/chat/completions\"\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        data = {\n",
    "          \"model\": \"DeepSeek-R1-Distill-Qwen-14B\",\n",
    "          #\"model\": \"DeepSeek-R1-Distill-Qwen-7B\",\n",
    "          #\"model\": \"DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "          \"messages\": [\n",
    "            {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": f\"당신은 전문 면접코치입니다. [{text}] 라는 질문에 대해 면접자가 [{transcribed_text}] 이라고 답했을 때에 아래 형식을 항상 준수하여 답변하세요. [답변 형식] [1. 답변의 긍정적 측면 : ~~~ 2. 답변의 개선할 점 : ~~~ 3. 개선된 면접자의 답변 : ~~~] 위와 같은답변 형식으로 총 300자 내외로 한국어로 번역하지 말고 영어로 답변하세요.\"\n",
    "            }\n",
    "          ],\n",
    "          \"max_tokens\": 2048,\n",
    "          \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = requests.post(API_URL, headers=headers, json=data)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        \n",
    "        try:\n",
    "            if response.status_code == 200 and response.text:\n",
    "                result = response.json()\n",
    "                answer = result['choices'][0]['message']['content']\n",
    "                # <think> 태그 제거\n",
    "                clean_text = re.sub(r'<think>.*?</think>', '', answer, flags=re.DOTALL).strip()\n",
    "                print(\"GPT4All 답변 (영어):\")\n",
    "                print(clean_text)\n",
    "        \n",
    "                print(\"\\n번역 중...\")\n",
    "                translated_answer = translate_text(clean_text, source_lang='en', target_lang='ko')\n",
    "                if translated_answer:\n",
    "                    print(\"\\n번역된 답변 (한국어):\")\n",
    "                    print(translated_answer)\n",
    "                else:\n",
    "                    print(\"번역 실패\")\n",
    "                    \n",
    "                print(f\"\\n질문-답변에 걸린 시간: {elapsed:.2f}초\")\n",
    "            else:\n",
    "                print('API 호출 실패:', response.status_code, response.text)\n",
    "        except Exception as e:\n",
    "            print('예외 발생:', e)\n",
    "            print('서버 응답 원문:', response.text)\n",
    "        # 결과 반환\n",
    "        return \"질문 : \" + text + \"stt : \" +transcribed_text + \"응답 : \" + translated_answer\n",
    "    except Exception as e:\n",
    "        error_traceback = traceback.format_exc()\n",
    "        # 예외 발생 시 임시 파일 정리\n",
    "        try:\n",
    "            if 'video_path' in locals() and os.path.exists(video_path):\n",
    "                os.unlink(video_path)\n",
    "            if 'audio_path' in locals() and audio_path and os.path.exists(audio_path):\n",
    "                os.unlink(audio_path)\n",
    "        finally:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": str(e),\n",
    "                \"traceback\": error_traceback\n",
    "            }\n",
    "# Jupyter notebook에서 서버 실행\n",
    "try:\n",
    "    nest_asyncio.apply()  # Jupyter 환경용\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, http='h11')\n",
    "except RuntimeError:\n",
    "    # 이미 실행 중인 이벤트 루프가 있으면 무시\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e91cd-aa92-4532-8e8a-a436668aa8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
