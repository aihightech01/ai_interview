{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a21bee-e955-430e-92a8-d2ad0ceeb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from mediapipe.python.solutions import face_detection as mp_face_detection\n",
    "import math\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# --- 설정 ---\n",
    "LOG_INTERVAL = 0.3\n",
    "PREDICT_INTERVAL = 1.0\n",
    "SOFTMAX_TEMPERATURE = 0.7\n",
    "NEUTRAL_DAMPING = 0.85\n",
    "BBOX_PAD_RATIO = 0.15\n",
    "SQUARE_CROP = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = \"trpakov/vit-face-expression\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name, use_fast=True)\n",
    "emo_model = AutoModelForImageClassification.from_pretrained(model_name).to(device)\n",
    "emo_model.eval()\n",
    "id2label = emo_model.config.id2label\n",
    "\n",
    "LABEL_ORDER = [id2label[i] for i in range(len(id2label))]\n",
    "face_detector = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
    "\n",
    "# Valence, Arousal weight maps\n",
    "VALENCE_MAP = {\n",
    "    \"angry\": -0.9,\n",
    "    \"disgust\": -0.7,\n",
    "    \"fear\": -0.8,\n",
    "    \"sad\": -0.9,\n",
    "    \"happy\": 0.9,\n",
    "    \"surprise\": 0.3,\n",
    "    \"neutral\": 0.0,\n",
    "}\n",
    "\n",
    "AROUSAL_MAP = {\n",
    "    \"angry\": 0.8,\n",
    "    \"disgust\": 0.4,\n",
    "    \"fear\": 0.9,\n",
    "    \"sad\": 0.2,\n",
    "    \"happy\": 0.7,\n",
    "    \"surprise\": 1.0,\n",
    "    \"neutral\": 0.1,\n",
    "}\n",
    "\n",
    "def clamp01(x):\n",
    "    return max(0.0, min(1.0, x))\n",
    "\n",
    "def toProbArrayFromObject(obj, labels=LABEL_ORDER):\n",
    "    probs_raw = [clamp01(obj.get(lb, 0.0) / 100.0) for lb in labels]\n",
    "    s = sum(probs_raw)\n",
    "    if s <= 0 or not math.isfinite(s):\n",
    "        return [0.0] * len(labels)\n",
    "    return [v / s for v in probs_raw]\n",
    "\n",
    "def entropy(probs):\n",
    "    eps = 1e-12\n",
    "    H = 0.0\n",
    "    for p in probs:\n",
    "        pp = max(p, eps)\n",
    "        H += -pp * math.log(pp)\n",
    "    return H\n",
    "\n",
    "def computeVAC(probs, labels=LABEL_ORDER):\n",
    "    K = len(probs)\n",
    "    vWeights = [VALENCE_MAP.get(lb, 0.0) for lb in labels]\n",
    "    aWeights = [AROUSAL_MAP.get(lb, 0.5) for lb in labels]\n",
    "\n",
    "    V = sum(p * v for p, v in zip(probs, vWeights))\n",
    "    A = sum(p * a for p, a in zip(probs, aWeights))\n",
    "    H = entropy(probs)\n",
    "    Hmax = math.log(max(K, 1))\n",
    "    C = 1 - (H / Hmax if Hmax > 0 else 0)\n",
    "    return V, clamp01(A), clamp01(C)\n",
    "\n",
    "def computeAESFromProbsObject(obj, labels=LABEL_ORDER):\n",
    "    probs = toProbArrayFromObject(obj, labels)\n",
    "    V, A, C = computeVAC(probs, labels)\n",
    "    Vn = (V + 1) / 2\n",
    "    AES = clamp01(0.4 * Vn + 0.4 * A + 0.2 * C)\n",
    "    return AES\n",
    "\n",
    "def get_boxes(frame_bgr):\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "    res = face_detector.process(cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB))\n",
    "    dets = res.detections if (res and res.detections) else []\n",
    "    boxes = []\n",
    "    for det in dets:\n",
    "        rb = det.location_data.relative_bounding_box\n",
    "        x1 = max(int(rb.xmin * w), 0)\n",
    "        y1 = max(int(rb.ymin * h), 0)\n",
    "        x2 = min(int((rb.xmin + rb.width) * w), w - 1)\n",
    "        y2 = min(int((rb.ymin + rb.height) * h), h - 1)\n",
    "        if x2 > x1 and y2 > y1:\n",
    "            cx = (x1 + x2) // 2\n",
    "            cy = (y1 + y2) // 2\n",
    "            bw = x2 - x1\n",
    "            bh = y2 - y1\n",
    "            side = max(bw, bh)\n",
    "            side = int(side * (1.0 + BBOX_PAD_RATIO))\n",
    "            if SQUARE_CROP:\n",
    "                half = side // 2\n",
    "                nx1 = max(cx - half, 0)\n",
    "                ny1 = max(cy - half, 0)\n",
    "                nx2 = min(nx1 + side, w - 1)\n",
    "                ny2 = min(ny1 + side, h - 1)\n",
    "                nx1 = max(nx2 - side, 0)\n",
    "                ny1 = max(ny2 - side, 0)\n",
    "                boxes.append((nx1, ny1, nx2, ny2))\n",
    "            else:\n",
    "                padw = int(bw * BBOX_PAD_RATIO * 0.5)\n",
    "                padh = int(bh * BBOX_PAD_RATIO * 0.5)\n",
    "                boxes.append((max(x1 - padw, 0), max(y1 - padh, 0),\n",
    "                              min(x2 + padw, w - 1), min(y2 + padh, h - 1)))\n",
    "    return boxes\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_emotion_probs(face_bgr, temperature=SOFTMAX_TEMPERATURE, neutral_damping=NEUTRAL_DAMPING):\n",
    "    face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_np = np.ascontiguousarray(face_rgb).astype(np.uint8)\n",
    "    inputs = processor(images=[img_np], return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    logits = emo_model(**inputs).logits\n",
    "    inv = {v: k for k, v in id2label.items()}\n",
    "    if \"neutral\" in inv:\n",
    "        neutral_idx = inv[\"neutral\"]\n",
    "        logits[:, neutral_idx] *= neutral_damping\n",
    "    logits = logits / max(1e-6, temperature)\n",
    "    probs = logits.softmax(dim=-1)[0].detach().cpu().numpy()\n",
    "    probs_dict = {id2label[i]: float(probs[i]) for i in range(len(probs))}\n",
    "    idx = int(np.argmax(probs))\n",
    "    top_label, top_score = id2label[idx], float(probs[idx])\n",
    "    return top_label, top_score, probs_dict\n",
    "\n",
    "def analyze_video_to_list(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return None, f\"Unable to open video: {video_path}\"\n",
    "    fps = 30\n",
    "    if fps <= 0: fps = 30.0\n",
    "    step = max(1, int(round(PREDICT_INTERVAL * fps)))\n",
    "    last_log_idx = -10**9\n",
    "    idx = 0\n",
    "    logs = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                break\n",
    "            if idx % step == 0:\n",
    "                boxes = get_boxes(frame)\n",
    "                if boxes:\n",
    "                    areas = [(x2 - x1) * (y2 - y1) for (x1, y1, x2, y2) in boxes]\n",
    "                    i = int(np.argmax(areas))\n",
    "                    x1, y1, x2, y2 = boxes[i]\n",
    "                    roi = frame[y1:y2, x1:x2].copy()\n",
    "                    top_label, top_score, probs_dict = predict_emotion_probs(roi)\n",
    "                    if (idx - last_log_idx) >= step:\n",
    "                        AES_score = computeAESFromProbsObject(probs_dict)\n",
    "                        score_100 = int(round(AES_score * 100)) \n",
    "                        iso_ts = datetime.now().isoformat(timespec=\"milliseconds\")\n",
    "                        log_entry = {\n",
    "                            \"frame_idx\": idx,\n",
    "                            \"score\": score_100,\n",
    "                        }\n",
    "                        for lab in LABEL_ORDER:\n",
    "                            log_entry[lab] = round(probs_dict.get(lab, 0.0) * 100.0, 2)\n",
    "                        logs.append(log_entry)\n",
    "                        last_log_idx = idx\n",
    "            idx += 1\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return logs, None\n",
    "\n",
    "@app.route('/analyze_video', methods=['POST'])\n",
    "def analyze_video_api():\n",
    "    data = request.json\n",
    "    video_path = data.get('video_path')\n",
    "    if not video_path:\n",
    "        return jsonify({\"error\": \"Missing 'video_path' in request body.\"}), 400\n",
    "\n",
    "    logs, error = analyze_video_to_list(video_path)\n",
    "    if error:\n",
    "        return jsonify({\"error\": error}), 500\n",
    "\n",
    "     # score 평균 계산\n",
    "    scores = [entry[\"score\"] for entry in logs if \"score\" in entry]\n",
    "    avg_score = int(round(sum(scores) / len(scores))) if scores else 0\n",
    "\n",
    "    return jsonify({\n",
    "        \"average_score\": avg_score,\n",
    "        \"results\": logs\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb03af-d2fe-48d7-a128-65b469c0f21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
